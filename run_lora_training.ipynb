{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Requirements & Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 23.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install -q -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Config & Training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import hf_hub_download\n",
    "\n",
    "realistic_vision_path = hf_hub_download(repo_id=\"SG161222/Realistic_Vision_V5.1_noVAE\", filename=\"Realistic_Vision_V5.1-inpainting.safetensors\")\n",
    "vae_path = hf_hub_download(repo_id=\"stabilityai/sd-vae-ft-mse-original\", filename=\"vae-ft-mse-840000-ema-pruned.safetensors\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ml_collections\n",
    "\n",
    "config = ml_collections.ConfigDict()\n",
    "\n",
    "## General\n",
    "config.seed = 2808\n",
    "config.logdir = \"logs\"\n",
    "config.global_caption = \"white-facades\"\n",
    "config.device = 'cuda'\n",
    "\n",
    "## Dataset\n",
    "config.dataset = dataset = ml_collections.ConfigDict()\n",
    "# Roboflow API key\n",
    "dataset.roboflow_api_key = 'HNXIsW3WwnidNDQZHexX'\n",
    "# Roboflow workspace\n",
    "dataset.roboflow_workspace = 'arked'\n",
    "# Roboflow project name\n",
    "dataset.project_name = 'white-facades'\n",
    "# Roboflow dataset version\n",
    "dataset.dataset_version = 1\n",
    "# Local path where the dataset is downloaded\n",
    "dataset.data_root = 'data'\n",
    "\n",
    "# Prompt\n",
    "config.prompt = prompt = ml_collections.ConfigDict()\n",
    "# Global caption to add to every prompt\n",
    "prompt.global_caption = 'white facades'\n",
    "\n",
    "# Model\n",
    "config.model = model = ml_collections.ConfigDict()\n",
    "model.model_path = realistic_vision_path\n",
    "model.vae_path = vae_path\n",
    "\n",
    "## Training\n",
    "config.train = train = ml_collections.ConfigDict()\n",
    "\n",
    "# LoRA hyperparameters\n",
    "train.lora_rank = 8\n",
    "train.lora_scale = 1.0\n",
    "train.lora_dropout_p = 0.1\n",
    "train.train_unet = True\n",
    "train.train_text_encoder = True\n",
    "train.unet_lr = 2e-4\n",
    "train.text_encoder_lr = 2e-4\n",
    "train.mask_temperature = 1.0\n",
    "\n",
    "# train batch size.\n",
    "train.train_batch_size = 2\n",
    "# eval batch size.\n",
    "train.eval_batch_size = 1\n",
    "# number of steps between saving model checkpoints.\n",
    "train.save_freq = 100\n",
    "# number of checkpoints to keep before overwriting old ones.\n",
    "train.num_checkpoint_limit = 5\n",
    "# mixed precision training. options are \"fp16\", \"bf16\", and \"no\". half-precision speeds up training significantly.\n",
    "train.mixed_precision = \"no\"\n",
    "# whether to use gradient checkpointing to reduce memory usage.\n",
    "train.gradient_checkpointing = False\n",
    "# number of gradient accumulation steps.\n",
    "train.gradient_accumulation_steps = 1\n",
    "# whether to use a learning rate schedule.\n",
    "train.use_scheduler = True\n",
    "# learning rate schedule type.\n",
    "train.scheduler_type = \"cosine_with_restarts\"\n",
    "# number of warmup steps for the learning rate schedule.\n",
    "train.scheduler_warmup_steps = 500\n",
    "# number of steps to train for.\n",
    "train.total_steps = 4000\n",
    "# learning rate.\n",
    "train.learning_rate = 1e-4\n",
    "# Adam beta1.\n",
    "train.adam_beta1 = 0.9\n",
    "# Adam beta2.\n",
    "train.adam_beta2 = 0.999\n",
    "# Adam weight decay.\n",
    "train.adam_weight_decay = 1e-4\n",
    "# Adam epsilon.\n",
    "train.adam_epsilon = 1e-8\n",
    "# clip gradients.\n",
    "train.clip_gradients = True\n",
    "# clip gradients max norm.\n",
    "train.clip_gradients_max_norm = 1.0\n",
    "# use xformers efficient attention\n",
    "train.use_xformers = True\n",
    "# checkpoint folder\n",
    "train.checkpoint_folder = \"checkpoints\"\n",
    "\n",
    "## Evaluation\n",
    "config.eval = eval = ml_collections.ConfigDict()\n",
    "# number of validation sample steps.\n",
    "eval.num_eval_steps = 20\n",
    "# whether to use a validation set.\n",
    "eval.use_validation = True\n",
    "# the prompts to use for validation.\n",
    "eval.prompts = ['']\n",
    "# the strengths to use for validation.\n",
    "eval.strenghts = [1.0]\n",
    "\n",
    "## Wandb\n",
    "# whether to use wandb.\n",
    "config.log_wandb = True\n",
    "# wandb project name.\n",
    "config.wandb = wandb = ml_collections.ConfigDict()\n",
    "# wandb project name.\n",
    "wandb.project_name = \"lora\"\n",
    "# wandb entity name.\n",
    "wandb.entity_name = \"arked\"\n",
    "# wandb run name. (if not set is assigned automatically)\n",
    "wandb.run_name = None\n",
    "# wandb tags.\n",
    "wandb.tags = [\"lora\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading Roboflow workspace...\n",
      "loading Roboflow project...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading Dataset Version Zip in data to yolov7pytorch:: 100%|██████████| 14915/14915 [00:00<00:00, 15768.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Extracting Dataset Version Zip to data in yolov7pytorch:: 100%|██████████| 775/775 [00:01<00:00, 733.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading VAE...\n",
      "loading model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"id2label\"]` will be overriden.\n",
      "A matching Triton is not available, some optimizations will not be enabled.\n",
      "Error caught was: No module named 'triton'\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mmaidacundo\u001b[0m (\u001b[33marked\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.15.12 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\Facundo\\Desktop\\ARKED\\training\\inpainting_training\\lora_inpainting\\wandb\\run-20231025_105834-146rm1k8</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/arked/lora/runs/146rm1k8' target=\"_blank\">atomic-field-1</a></strong> to <a href='https://wandb.ai/arked/lora' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/arked/lora' target=\"_blank\">https://wandb.ai/arked/lora</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/arked/lora/runs/146rm1k8' target=\"_blank\">https://wandb.ai/arked/lora/runs/146rm1k8</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unet LoRA params: 2492928\n",
      "CLIP LoRA params: 589824\n",
      "Directory 'checkpoints' created.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Steps:   0%|          | 0/4000 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "from src.training import train\n",
    "\n",
    "train(config)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
