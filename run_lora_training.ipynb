{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Requirements & Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 23.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install -q -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Config & Training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import hf_hub_download\n",
    "\n",
    "realistic_vision_path = hf_hub_download(repo_id=\"SG161222/Realistic_Vision_V5.1_noVAE\", filename=\"Realistic_Vision_V5.1-inpainting.safetensors\")\n",
    "vae_path = hf_hub_download(repo_id=\"stabilityai/sd-vae-ft-mse-original\", filename=\"vae-ft-mse-840000-ema-pruned.safetensors\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: roboflow in c:\\users\\facundo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (1.1.7)\n",
      "Requirement already satisfied: certifi==2022.12.7 in c:\\users\\facundo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from roboflow) (2022.12.7)\n",
      "Requirement already satisfied: chardet==4.0.0 in c:\\users\\facundo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from roboflow) (4.0.0)\n",
      "Requirement already satisfied: cycler==0.10.0 in c:\\users\\facundo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from roboflow) (0.10.0)\n",
      "Requirement already satisfied: idna==2.10 in c:\\users\\facundo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from roboflow) (2.10)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\facundo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from roboflow) (1.4.5)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\facundo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from roboflow) (3.8.0)\n",
      "Requirement already satisfied: numpy>=1.18.5 in c:\\users\\facundo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from roboflow) (1.23.5)\n",
      "Requirement already satisfied: opencv-python-headless==4.8.0.74 in c:\\users\\facundo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from roboflow) (4.8.0.74)\n",
      "Requirement already satisfied: Pillow>=7.1.2 in c:\\users\\facundo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from roboflow) (9.5.0)\n",
      "Requirement already satisfied: pyparsing==2.4.7 in c:\\users\\facundo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from roboflow) (2.4.7)\n",
      "Requirement already satisfied: python-dateutil in c:\\users\\facundo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from roboflow) (2.8.2)\n",
      "Requirement already satisfied: python-dotenv in c:\\users\\facundo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from roboflow) (1.0.0)\n",
      "Requirement already satisfied: requests in c:\\users\\facundo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from roboflow) (2.31.0)\n",
      "Requirement already satisfied: six in c:\\users\\facundo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from roboflow) (1.16.0)\n",
      "Requirement already satisfied: supervision in c:\\users\\facundo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from roboflow) (0.14.0)\n",
      "Requirement already satisfied: urllib3>=1.26.6 in c:\\users\\facundo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from roboflow) (1.26.16)\n",
      "Requirement already satisfied: tqdm>=4.41.0 in c:\\users\\facundo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from roboflow) (4.66.1)\n",
      "Requirement already satisfied: PyYAML>=5.3.1 in c:\\users\\facundo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from roboflow) (6.0.1)\n",
      "Requirement already satisfied: requests-toolbelt in c:\\users\\facundo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from roboflow) (1.0.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\facundo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tqdm>=4.41.0->roboflow) (0.4.6)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\facundo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib->roboflow) (1.1.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\facundo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib->roboflow) (4.42.1)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\facundo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib->roboflow) (23.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\facundo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->roboflow) (3.2.0)\n",
      "Requirement already satisfied: scipy<2.0.0,>=1.9.0 in c:\\users\\facundo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from supervision->roboflow) (1.11.3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 23.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading Roboflow workspace...\n",
      "loading Roboflow project...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading Dataset Version Zip in kvist_windows-3 to yolov7pytorch:: 100%|██████████| 8789/8789 [00:00<00:00, 11890.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Extracting Dataset Version Zip to kvist_windows-3 in yolov7pytorch:: 100%|██████████| 83/83 [00:00<00:00, 741.28it/s]\n"
     ]
    }
   ],
   "source": [
    "!pip install roboflow\n",
    "\n",
    "from roboflow import Roboflow\n",
    "rf = Roboflow(api_key=\"HNXIsW3WwnidNDQZHexX\")\n",
    "project = rf.workspace(\"arked\").project(\"kvist_windows\")\n",
    "dataset = project.version(3).download(\"yolov7\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ml_collections\n",
    "\n",
    "config = ml_collections.ConfigDict()\n",
    "\n",
    "## General\n",
    "config.seed = 2808\n",
    "config.logdir = \"logs\"\n",
    "config.device = 'cuda'\n",
    "\n",
    "## Dataset\n",
    "config.dataset = dataset = ml_collections.ConfigDict()\n",
    "# Roboflow API key\n",
    "dataset.roboflow_api_key = 'HNXIsW3WwnidNDQZHexX'\n",
    "# Roboflow workspace\n",
    "dataset.roboflow_workspace = 'arked'\n",
    "# Roboflow project name\n",
    "dataset.project_name = 'kvist_windows'\n",
    "# Roboflow dataset version\n",
    "dataset.dataset_version = 3\n",
    "# Local path where the dataset is downloaded\n",
    "dataset.data_root = 'data'\n",
    "# image size\n",
    "dataset.image_size = 512\n",
    "# max image size\n",
    "dataset.max_image_size = 512\n",
    "# normalize images\n",
    "dataset.normalize_images = True\n",
    "# scaling pixels of the mask\n",
    "dataset.scaling_pixels = 4\n",
    "\n",
    "# Prompt\n",
    "config.prompt = prompt = ml_collections.ConfigDict()\n",
    "# Global caption to add to every prompt\n",
    "prompt.global_caption = None\n",
    "prompt.negative_caption = 'ugly, blurry, poor quality'\n",
    "\n",
    "# Model\n",
    "config.model = model = ml_collections.ConfigDict()\n",
    "model.model_path = realistic_vision_path\n",
    "model.vae_path = vae_path\n",
    "\n",
    "## Training\n",
    "config.train = train = ml_collections.ConfigDict()\n",
    "\n",
    "# LoRA hyperparameters\n",
    "train.lora_rank = 8\n",
    "train.lora_scale = 1.0\n",
    "train.lora_dropout_p = 0.1\n",
    "train.train_unet = True\n",
    "train.train_text_encoder = True\n",
    "train.unet_lr = 2e-4\n",
    "train.text_encoder_lr = 2e-4\n",
    "train.mask_temperature = 1.0\n",
    "\n",
    "# train batch size.\n",
    "train.train_batch_size = 2\n",
    "# eval batch size.\n",
    "train.eval_batch_size = 1\n",
    "\n",
    "# number of steps of the noise scheduler\n",
    "train.num_train_timesteps = 50\n",
    "# TODO add noise scheduler type and hyperparameters\n",
    "\"\"\" \n",
    "{\n",
    "  \"_class_name\": \"DEISMultistepScheduler\",\n",
    "  \"_diffusers_version\": \"0.16.1\",\n",
    "  \"algorithm_type\": \"deis\",\n",
    "  \"beta_end\": 0.012,\n",
    "  \"beta_schedule\": \"scaled_linear\",\n",
    "  \"beta_start\": 0.00085,\n",
    "  \"clip_sample\": false,\n",
    "  \"clip_sample_range\": 1.0,\n",
    "  \"dynamic_thresholding_ratio\": 0.995,\n",
    "  \"lower_order_final\": true,\n",
    "  \"num_train_timesteps\": 1000,\n",
    "  \"prediction_type\": \"epsilon\",\n",
    "  \"sample_max_value\": 1.0,\n",
    "  \"set_alpha_to_one\": false,\n",
    "  \"solver_order\": 2,\n",
    "  \"solver_type\": \"logrho\",\n",
    "  \"steps_offset\": 1,\n",
    "  \"thresholding\": false,\n",
    "  \"trained_betas\": null\n",
    "}\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# number of steps between evaluating and saving model checkpoints.\n",
    "train.eval_every_n_epochs = 5\n",
    "# number of checkpoints to keep before overwriting old ones.\n",
    "train.num_checkpoint_limit = 5\n",
    "# mixed precision training. options are \"fp16\", \"bf16\", and \"no\". half-precision speeds up training significantly.\n",
    "train.mixed_precision = \"no\"\n",
    "# whether to use gradient checkpointing to reduce memory usage.\n",
    "train.gradient_checkpointing = False\n",
    "# number of gradient accumulation steps.\n",
    "train.gradient_accumulation_steps = 1\n",
    "# whether to use a learning rate schedule.\n",
    "train.use_scheduler = True\n",
    "# learning rate schedule type.\n",
    "train.scheduler_type = \"cosine_with_restarts\"\n",
    "# num_cycles for the learning rate schedule.\n",
    "train.scheduler_num_cycles = 2\n",
    "# number of warmup steps for the learning rate schedule.\n",
    "train.scheduler_warmup_steps = 500\n",
    "# number of steps to train for.\n",
    "train.total_steps = 4000\n",
    "# learning rate.\n",
    "train.learning_rate = 1e-4\n",
    "# Adam beta1.\n",
    "train.adam_beta1 = 0.9\n",
    "# Adam beta2.\n",
    "train.adam_beta2 = 0.999\n",
    "# Adam weight decay.\n",
    "train.adam_weight_decay = 1e-4\n",
    "# Adam epsilon.\n",
    "train.adam_epsilon = 1e-8\n",
    "# clip gradients.\n",
    "train.clip_gradients = True\n",
    "# clip gradients max norm.\n",
    "train.clip_gradients_max_norm = 1.0\n",
    "# use xformers efficient attention\n",
    "train.use_xformers = True\n",
    "# checkpoint folder\n",
    "train.checkpoint_folder = \"checkpoints\"\n",
    "\n",
    "## Evaluation\n",
    "config.eval = eval = ml_collections.ConfigDict()\n",
    "# number of validation sample steps.\n",
    "eval.num_eval_steps = 20\n",
    "# whether to use a validation set.\n",
    "eval.use_validation = True\n",
    "# the prompts to use for validation.\n",
    "eval.prompts = ['']\n",
    "# the strengths to use for validation.\n",
    "eval.strengths = [1.0]\n",
    "# eval epochs number.\n",
    "eval.eval_epochs = 10\n",
    "\n",
    "## Wandb\n",
    "# whether to use wandb.\n",
    "config.log_wandb = True\n",
    "# wandb project name.\n",
    "config.wandb = wandb = ml_collections.ConfigDict()\n",
    "# wandb project name.\n",
    "wandb.project_name = \"kvist_windows\"\n",
    "# wandb entity name.\n",
    "wandb.entity_name = \"arked\"\n",
    "# wandb run name. (if not set is assigned automatically)\n",
    "wandb.run_name = None\n",
    "# wandb tags.\n",
    "wandb.tags = [\"lora\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The torchvision.datapoints and torchvision.transforms.v2 namespaces are still Beta. While we do not expect major breaking changes, some APIs may still change according to user feedback. Please submit any feedback you may have in this issue: https://github.com/pytorch/vision/issues/6753, and you can also check out https://github.com/pytorch/vision/issues/7319 to learn more about the APIs that we suspect might involve future changes. You can silence this warning by calling torchvision.disable_beta_transforms_warning().\n",
      "The torchvision.datapoints and torchvision.transforms.v2 namespaces are still Beta. While we do not expect major breaking changes, some APIs may still change according to user feedback. Please submit any feedback you may have in this issue: https://github.com/pytorch/vision/issues/6753, and you can also check out https://github.com/pytorch/vision/issues/7319 to learn more about the APIs that we suspect might involve future changes. You can silence this warning by calling torchvision.disable_beta_transforms_warning().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading Roboflow workspace...\n",
      "loading Roboflow project...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading Dataset Version Zip in data to yolov7pytorch:: 100%|██████████| 8789/8789 [00:00<00:00, 11800.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Extracting Dataset Version Zip to data in yolov7pytorch:: 100%|██████████| 83/83 [00:00<00:00, 1035.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading VAE...\n",
      "loading model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"id2label\"]` will be overriden.\n",
      "The class CLIPFeatureExtractor is deprecated and will be removed in version 5 of Transformers. Please use CLIPImageProcessor instead.\n",
      "The transform `ToTensor()` is deprecated and will be removed in a future release. Instead, please use `transforms.Compose([transforms.ToImageTensor(), transforms.ConvertImageDtype()])`.\n",
      "A matching Triton is not available, some optimizations will not be enabled.\n",
      "Error caught was: No module named 'triton'\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mmaidacundo\u001b[0m (\u001b[33marked\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.15.12 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\Facundo\\Desktop\\ARKED\\training\\inpainting_training\\lora_inpainting\\wandb\\run-20231027_132118-vjr94inn</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/arked/kvist_windows/runs/vjr94inn' target=\"_blank\">toasty-sound-5</a></strong> to <a href='https://wandb.ai/arked/kvist_windows' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/arked/kvist_windows' target=\"_blank\">https://wandb.ai/arked/kvist_windows</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/arked/kvist_windows/runs/vjr94inn' target=\"_blank\">https://wandb.ai/arked/kvist_windows/runs/vjr94inn</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unet LoRA params: 2492928\n",
      "CLIP LoRA params: 589824\n",
      "Directory 'checkpoints' already exists.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Steps:   0%|          | 2/4000 [01:02<36:29:52, 32.86s/it, loss_lora=0.000256, lr=8e-7]"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">╭─────────────────────────────── </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Traceback </span><span style=\"color: #bf7f7f; text-decoration-color: #bf7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #800000; text-decoration-color: #800000\"> ────────────────────────────────╮</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;module&gt;</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">3</span>                                                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1 </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">from</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff; text-decoration: underline\">src.training</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">import</span> train                                                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2 </span>                                                                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>3 train(config)                                                                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">4 </span>                                                                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000\">c:\\Users\\Facundo\\Desktop\\ARKED\\training\\inpainting_training\\lora_inpainting\\src\\training.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">171</span>  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">train</span>                                                                                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">168 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">for</span> epoch <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">in</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">range</span>(math.ceil(config.train.total_steps / <span style=\"color: #00ffff; text-decoration-color: #00ffff\">len</span>(train_dataloader))):       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">169 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">for</span> batch <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">in</span> train_dataloader:                                                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">170 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>optimizer_lora.zero_grad()                                                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>171 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>loss_lora = loss_step(                                                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">172 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span>batch,                                                                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">173 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span>unet,                                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">174 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span>vae,                                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000\">c:\\Users\\Facundo\\Desktop\\ARKED\\training\\inpainting_training\\lora_inpainting\\src\\training.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">284</span>  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">loss_step</span>                                                                                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">281 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>                                                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">282 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># scale the mask</span>                                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">283 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>mask = F.interpolate(                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>284 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span>batch[<span style=\"color: #808000; text-decoration-color: #808000\">\"mask\"</span>].to(dtype=weight_dtype).to(unet.device),                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">285 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span>scale_factor=<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1</span> / <span style=\"color: #0000ff; text-decoration-color: #0000ff\">8</span>,                                                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">286 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>)                                                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">287 </span>                                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">╰──────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">KeyboardInterrupt</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[31m╭─\u001b[0m\u001b[31m──────────────────────────────\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31m───────────────────────────────\u001b[0m\u001b[31m─╮\u001b[0m\n",
       "\u001b[31m│\u001b[0m in \u001b[92m<module>\u001b[0m:\u001b[94m3\u001b[0m                                                                                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1 \u001b[0m\u001b[94mfrom\u001b[0m \u001b[4;96msrc\u001b[0m\u001b[4;96m.\u001b[0m\u001b[4;96mtraining\u001b[0m \u001b[94mimport\u001b[0m train                                                               \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m2 \u001b[0m                                                                                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m3 train(config)                                                                                \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m4 \u001b[0m                                                                                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[33mc:\\Users\\Facundo\\Desktop\\ARKED\\training\\inpainting_training\\lora_inpainting\\src\\training.py\u001b[0m:\u001b[94m171\u001b[0m  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m in \u001b[92mtrain\u001b[0m                                                                                         \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m168 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mfor\u001b[0m epoch \u001b[95min\u001b[0m \u001b[96mrange\u001b[0m(math.ceil(config.train.total_steps / \u001b[96mlen\u001b[0m(train_dataloader))):       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m169 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mfor\u001b[0m batch \u001b[95min\u001b[0m train_dataloader:                                                     \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m170 \u001b[0m\u001b[2m│   │   │   \u001b[0moptimizer_lora.zero_grad()                                                     \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m171 \u001b[2m│   │   │   \u001b[0mloss_lora = loss_step(                                                         \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m172 \u001b[0m\u001b[2m│   │   │   │   \u001b[0mbatch,                                                                     \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m173 \u001b[0m\u001b[2m│   │   │   │   \u001b[0munet,                                                                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m174 \u001b[0m\u001b[2m│   │   │   │   \u001b[0mvae,                                                                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[33mc:\\Users\\Facundo\\Desktop\\ARKED\\training\\inpainting_training\\lora_inpainting\\src\\training.py\u001b[0m:\u001b[94m284\u001b[0m  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m in \u001b[92mloss_step\u001b[0m                                                                                     \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m281 \u001b[0m\u001b[2m│   \u001b[0m                                                                                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m282 \u001b[0m\u001b[2m│   \u001b[0m\u001b[2m# scale the mask\u001b[0m                                                                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m283 \u001b[0m\u001b[2m│   \u001b[0mmask = F.interpolate(                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m284 \u001b[2m│   │   │   │   \u001b[0mbatch[\u001b[33m\"\u001b[0m\u001b[33mmask\u001b[0m\u001b[33m\"\u001b[0m].to(dtype=weight_dtype).to(unet.device),                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m285 \u001b[0m\u001b[2m│   │   │   │   \u001b[0mscale_factor=\u001b[94m1\u001b[0m / \u001b[94m8\u001b[0m,                                                        \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m286 \u001b[0m\u001b[2m│   │   │   \u001b[0m)                                                                              \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m287 \u001b[0m                                                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n",
       "\u001b[1;91mKeyboardInterrupt\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from src.training import train\n",
    "\n",
    "train(config)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
