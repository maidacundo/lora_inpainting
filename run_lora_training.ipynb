{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Requirements & Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../src')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 23.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install -q -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Config & Training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import hf_hub_download\n",
    "\n",
    "# realistic_vision_path = hf_hub_download(repo_id=\"SG161222/Realistic_Vision_V6.0_B1_noVAE\", filename=\"Realistic_Vision_V6.0_NV_B1_inpainting.safetensors\")\n",
    "realistic_vision_path = hf_hub_download(repo_id=\"SG161222/Realistic_Vision_V5.1_noVAE\", filename=\"Realistic_Vision_V5.1-inpainting.safetensors\")\n",
    "vae_path = hf_hub_download(repo_id=\"stabilityai/sd-vae-ft-mse-original\", filename=\"vae-ft-mse-840000-ema-pruned.safetensors\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.config import DatasetConfig, Config, ModelConfig, WandbConfig, EvaluationConfig, TrainConfig, LoraConfig, PromptConfig\n",
    "\n",
    "dataset_config = DatasetConfig(\n",
    "    roboflow_api_key='HNXIsW3WwnidNDQZHexX',\n",
    "    roboflow_workspace='arked',\n",
    "    project_name='kvist_windows',\n",
    "    dataset_version=7,\n",
    "    image_size=512,\n",
    "    normalize_images=False,\n",
    "    scaling_pixels=25,\n",
    ")\n",
    "\n",
    "model_config = ModelConfig(\n",
    "    model_path=realistic_vision_path,\n",
    "    vae_path=vae_path,\n",
    ")\n",
    "\n",
    "wandb_config = WandbConfig(\n",
    "    project_name='kvist_windows',\n",
    "    entity_name='maidacundo',\n",
    "    run_name='test_hough_loss',\n",
    ") \n",
    "\n",
    "eval_config=EvaluationConfig(\n",
    "    prompts=['kvist windows'],\n",
    "    eval_epochs=20,\n",
    ")\n",
    "\n",
    "train_config=TrainConfig(\n",
    "    checkpoint_folder=wandb_config.project_name + \"_checkpoints\",\n",
    "    train_batch_size=4,\n",
    "    unet_lr=3e-4,\n",
    "    text_encoder_lr=3e-4,\n",
    "    learning_rate=1e-3,\n",
    "    scheduler_num_cycles=2,\n",
    "    lora_total_steps=2000,\n",
    "    ti_total_steps=1000,\n",
    "    scheduler_warmup_steps=100,\n",
    "    criterion='mlsd',\n",
    ")\n",
    "\n",
    "lora_config=LoraConfig(\n",
    "    rank=8,\n",
    "    alpha=1,\n",
    ")\n",
    "\n",
    "config = Config(\n",
    "    dataset=dataset_config,\n",
    "    model=model_config,\n",
    "    wandb=wandb_config,\n",
    "    eval=eval_config,\n",
    "    train=train_config,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.training import train\n",
    "\n",
    "train(config)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
